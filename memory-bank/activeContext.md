# アクティブコンテキスト

## 現在の焦点（2025-05-01更新）

### OpenAIモデルドキュメントの追加
- 'docs/guides/models.md' に OpenAI モデルの情報を追加
- モデルID、正式名称、説明を含む表形式での記載
- 使用例とバッチ処理コマンドの追加
- 推論モデルの制約事項を明記

### Llamaモデルチェック機能の実装完了
- check_models.pyにLlamaモデルのチェック機能を追加
- kluster.ai APIを使用した実装
- DeepSeek実装パターンの活用
- LLAMA_MODELSの各モデルのチェック機能

### 複数モデル選択機能の実装
- 全モデルのexampleスクリプトに--modelオプションを追加
- 個別モデルの選択的実行が可能に
- コマンドライン引数による柔軟な実験制御
- 共通のインターフェース設計

### ClaudeバッチAPIの改善（2025-04-25追加）
1. PromptManager統合
   - システム/ユーザーメッセージの分離実装
   - 温度制御機能の統合
   - プロンプト生成の標準化

2. バッチ処理の最適化
   - モデル選択機能の完全対応
   - 温度パラメータの一貫した処理
   - カスタムIDの標準形式対応

3. 結果保存の改善
   - メタデータの一貫性確保
   - 温度値の正確な記録
   - エラー処理の強化

### Gemini 2.5シリーズの実験完了
- Gemini 2.5 Flash Previewモデルでの実験実施：
  - gemini-2.5-flash-preview-04-17
  - 高速処理と効率的なバッチ処理を確認
  - 標準フォーマットへの完全準拠を確認

### 最新の実験結果（2025-04-19）
1. Gemini 2.5シリーズの実験結果
   - 追加40ファイルの生成完了（1モデル × 4ペルソナ × 1テキスト × 10トライアル）
   - バッチ処理の安定性を確認
   - パターンマッチングによる応答形式の一貫性確保

2. 結果の検証と変換
   - 標準フォーマットへの変換完了
   - メタデータの整合性確認
   - 温度パラメータの正常な記録
   - パフォーマンス指標の収集

### 前回の実験結果（2025-04-17）
1. GPT-4.1シリーズの実験結果
   - 全360ファイルの生成完了（3モデル × 4ペルソナ × 3テキスト × 10トライアル）
   - バッチ処理による50%のコスト削減達成
   - すべてのモデルで標準フォーマットに準拠
   - パターンマッチングによる応答形式の一貫性確保

2. 結果の検証と変換
   - JSONLからテキストファイルへの変換完了
   - メタデータの整合性確認
   - 温度パラメータの正常な記録
   - 価格情報の追跡と分析

### 結果ファイル形式の統一（2025-05-01追加）
1. 識別子形式への変更
   - `persona` と `text` フィールドを識別子形式（p1, t1 など）に変更
   - すべての実験ランナー（Gemini、Grok、Claude など）に適用

2. パラメータ順序の統一
   - 結果ファイルのパラメータ順序を以下のように統一：
     - timestamp
     - text
     - model
     - persona
     - temperature (条件付き)
     - trial

### 次のステップ：他モデルへの展開

1. Claude実験の開始
   - Message Batches APIの活用
   - 最大100,000リクエスト対応
   - スロットリング（100リクエスト/分）の考慮
   - 29日間の結果保持期間の活用

2. DeepSeek実験の準備
   - kluster.ai APIを使用した実験設計
   - OpenAI互換インターフェースの活用
   - R1, V3, V3-0324モデルの評価計画

3. Llama実験の計画
   - 3つのモデルサイズ（70B, 405B, 8B）での評価
   - kluster.ai経由でのバッチ処理
   - 24時間処理ウィンドウの最適化

4. ドキュメントの整合性確保
   - 他のモデルのドキュメント更新
   - README.md やその他のガイドとの一貫性確認

5. temperature_support の問題解決（2025-05-01追加）
   - 'parameters.py' の OPENAI_MODELS に gpt-4o と gpt-4o-mini に対して "temperature_support": True を追加
   - 'experiment_runner.py' の OpenAIExperimentRunner クラスに temperature_support をチェックするロジックを追加
   - 結果ファイルに temperature が正しく記録されるように修正

## 実装の改善点

1. バッチ処理の最適化
   - GPT-4.1シリーズでの知見を他モデルに適用
   - エラーハンドリングの強化
   - 処理効率の向上
   - コスト効率の最適化

2. 品質管理の強化
   - パターンマッチングの適用範囲拡大
   - 応答形式の厳密な検証
   - エラー検出の精度向上
   - 自動再試行メカニズムの改善

3. 複数モデル選択機能の完全実装
   - DeepSeekとLlamaのバッチ処理exampleに--modelオプションを追加
   - 他exampleスクリプトとの一貫性確保
   - コマンドライン引数による柔軟なモデル指定

4. ドキュメントの整合性確保
   - README.md、docs/guides/models.md、features.md、batch-processing.mdの更新完了
   - ユーザーフレンドリーな説明文の整備
   - バッチ処理の実装・実行方法の明記

## 技術的な考慮事項（2025-04-24更新）

### アーキテクチャ
- コマンドラインインターフェースの統一
- モデル選択機能の標準化
- バッチ処理システムの信頼性確認
- 結果変換プロセスの安定性
- スケーラブルな実験管理
- 異なるAPIへの適応性
- Gemini 2.5対応の統合

### 依存関係
- Python 3.12
- OpenAI、Claude、kluster.aiのSDKs
- google-generativeai>=0.3.0（Gemini 2.5対応）
- バッチ処理ツール群
- 結果変換ユーティリティ

### 制約と考慮点
- APIごとの制限の考慮
- 処理時間の最適化
- コスト効率の維持
- データ品質の確保
- モデル別の特性対応
- コマンドライン引数の一貫性
