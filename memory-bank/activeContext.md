# アクティブコンテキスト

## 現在の焦点（2025-04-24更新）

### 複数モデル選択機能の実装
- 全モデルのexampleスクリプトに--modelオプションを追加
- 個別モデルの選択的実行が可能に
- コマンドライン引数による柔軟な実験制御
- 共通のインターフェース設計

### Gemini 2.5シリーズの実験完了
- Gemini 2.5 Flash Previewモデルでの実験実施：
  - gemini-2.5-flash-preview-04-17
  - 高速処理と効率的なバッチ処理を確認
  - 標準フォーマットへの完全準拠を確認

### 最新の実験結果（2025-04-19）
1. Gemini 2.5シリーズの実験結果
   - 追加40ファイルの生成完了（1モデル × 4ペルソナ × 1テキスト × 10トライアル）
   - バッチ処理の安定性を確認
   - パターンマッチングによる応答形式の一貫性確保

2. 結果の検証と変換
   - 標準フォーマットへの変換完了
   - メタデータの整合性確認
   - 温度パラメータの正常な記録
   - パフォーマンス指標の収集

### 前回の実験結果（2025-04-17）
1. GPT-4.1シリーズの実験結果
   - 全360ファイルの生成完了（3モデル × 4ペルソナ × 3テキスト × 10トライアル）
   - バッチ処理による50%のコスト削減達成
   - すべてのモデルで標準フォーマットに準拠
   - パターンマッチングによる応答形式の一貫性確保

2. 結果の検証と変換
   - JSONLからテキストファイルへの変換完了
   - メタデータの整合性確認
   - 温度パラメータの正常な記録
   - 価格情報の追跡と分析

### 次のステップ：他モデルへの展開

1. Claude実験の開始
   - Message Batches APIの活用
   - 最大100,000リクエスト対応
   - スロットリング（100リクエスト/分）の考慮
   - 29日間の結果保持期間の活用

2. DeepSeek実験の準備
   - kluster.ai APIを使用した実験設計
   - OpenAI互換インターフェースの活用
   - R1, V3, V3-0324モデルの評価計画

3. Llama実験の計画
   - 3つのモデルサイズ（70B, 405B, 8B）での評価
   - kluster.ai経由でのバッチ処理
   - 24時間処理ウィンドウの最適化

## 実装の改善点

1. バッチ処理の最適化
   - GPT-4.1シリーズでの知見を他モデルに適用
   - エラーハンドリングの強化
   - 処理効率の向上
   - コスト効率の最適化

2. 品質管理の強化
   - パターンマッチングの適用範囲拡大
   - 応答形式の厳密な検証
   - エラー検出の精度向上
   - 自動再試行メカニズムの改善

## 技術的な考慮事項（2025-04-24更新）

### アーキテクチャ
- コマンドラインインターフェースの統一
- モデル選択機能の標準化
- バッチ処理システムの信頼性確認
- 結果変換プロセスの安定性
- スケーラブルな実験管理
- 異なるAPIへの適応性
- Gemini 2.5対応の統合

### 依存関係
- Python 3.12
- OpenAI、Claude、kluster.aiのSDKs
- google-generativeai>=0.3.0（Gemini 2.5対応）
- バッチ処理ツール群
- 結果変換ユーティリティ

### 制約と考慮点
- APIごとの制限の考慮
- 処理時間の最適化
- コスト効率の維持
- データ品質の確保
- モデル別の特性対応
- コマンドライン引数の一貫性
