# 機能ガイド

## コア機能

### 文学解析
- LLMによる文学作品の理解度評価
- 感情分析（面白さ、驚き、悲しみ、怒り）
- 定量的スコアリング（0-100）
- 理由付けの自動生成

### マルチモデル対応
- 複数のLLMプロバイダーのサポート
- モデル固有の最適化
- 統一されたインターフェース
- 結果の標準化と比較

## 統一プロンプト管理

### 基本設計
- 一元化されたプロンプト定義
- モデル固有のフォーマット適応
- システムメッセージとユーザーメッセージの分離
- 再利用可能なテンプレート

### モデル別の対応（2025-04-19更新）
1. 標準メッセージフォーマット
   - Gemini 2.5シリーズ（新規追加）
   - OpenAI GPT-4.1シリーズ
   - Gemini 2.0/1.5シリーズ
   - Grok
   - その他の標準モデル

2. 特殊フォーマット
   - Claude：コンテンツフォーマット
   - o1-mini：システムロール制限
   - o3-mini：温度パラメータ制限

### プロンプト検証
- 形式の自動チェック
- 必須要素の確認
- エラー検出と報告
- 自動修正の提案

## 温度制御システム

### ペルソナベース制御
各ペルソナの特性に基づく基本温度設定：
- 大学1年生（0.7）：柔軟な発想を促進
- 文学研究者（0.4）：論理的分析を重視
- 感情豊かな詩人（0.9）：創造性を最大化
- 無感情なロボット（0.1）：決定論的な応答

### テキスト特性による調整
テキストの性質に応じた温度修正：
- 寓話的テキスト：±0.1
- 物語的テキスト：±0.2
- 詩的テキスト：±0.3

### 計算ロジック
- 基本温度の適用
- テキスト特性による修正
- 最終温度の範囲チェック
- モデル固有の制約対応

## 結果分析システム

### 感情次元の分析
1. 数値評価（0-100）
   - 面白さ：テキストの魅力度
   - 驚き：意外性や新規性
   - 悲しみ：悲嘆や喪失感
   - 怒り：不満や憤りの程度

2. 理由付けの生成
   - 具体的な根拠の提示
   - テキストからの引用
   - 解釈の妥当性説明

### 自動集計機能
- モデル別の統計
- ペルソナ間の比較
- テキスト種別の分析
- 時系列でのトレンド

### 品質管理
- 応答の一貫性チェック
- 数値範囲の検証
- 理由付けの充実度評価
- エラーケースの検出

## バッチ処理システム（2025-04-19更新）

### モデル別の最適化
1. Gemini 2.5シリーズ
   - 高速処理モードの活用
   - バッチ処理の安定性向上
   - 効率的なリソース使用

2. GPT-4.1シリーズ
   - コスト最適化：
     - gpt-4.1（高精度）：
       - Input: $2.00
       - Cached input: $0.50（キャッシュ利用による75%削減）
       - Output: $8.00
     - gpt-4.1-mini（中規模）：
       - Input: $0.40
       - Cached input: $0.10（キャッシュ利用による75%削減）
       - Output: $1.60
     - gpt-4.1-nano（軽量）：
       - Input: $0.10
       - Cached input: $0.025（キャッシュ利用による75%削減）
       - Output: $0.40

### バッチ処理の改善
1. 基本機能
   - JSONLフォーマットの活用
   - 50%のコスト削減を実現
   - キャッシュ入力の利用
   - リソースの効率的な使用

2. 最適化戦略
   - モデル別の最適バッチサイズ
   - 並列処理の効率化
   - メモリ使用量の制御
   - 処理時間の最適化

### プロバイダー別の実装
1. OpenAI
   a. GPT-4.1シリーズ
      - 高精度から軽量まで3つのモデル
      - バッチ処理による50%コスト削減
      - キャッシュ入力による追加75%削減
      - 高効率なバッチ最適化
   
   b. 従来モデル
      - 標準モデルのサポート
      - 推論モデルの特殊処理
      - 自動エラー回復
      - 結果の自動変換

2. Gemini（2025-04-19更新）
   - 2.5シリーズの高速処理対応
   - バッチ処理の安定性向上
   - 効率的なリソース使用
   - フォーマット統一化

3. Claude
   - Message Batches API対応
   - 100,000リクエスト上限
   - 29日間の結果保持
   - レート制限の管理

4. kluster.ai
   - DeepSeekモデル対応
   - Llamaモデル対応
   - 24時間処理ウィンドウ
   - OpenAI互換インターフェース

### エラーハンドリング
- モデル固有のエラー処理
- バックオフ付き自動リトライ
- 部分的失敗からの回復
- 詳細なエラーログ
