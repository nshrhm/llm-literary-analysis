# 既知の課題

## API制限と費用

- 同時実行可能なリクエスト数に制限あり:
  - Claude: 5 requests/minute
  - Gemini: 60 requests/minute
  - Grok: 10 requests/minute
  - OpenAI: モデルタイプにより異なる（3-50 requests/minute）
- API使用量に応じた費用の発生:
  - プロバイダごとに異なる価格体系
  - 高性能モデルほど高コスト
- 大規模な実験実行時のコスト最適化:
  - バッチ処理の利用
  - 並列実行の制御
  - 使用量モニタリング

## モデル可用性とバージョン管理

- LLMモデルの利用可能性:
  - プロバイダごとに異なるモデルのライフサイクル
  - 新モデルリリース時の対応（特にGemini/Claude）
  - 古いモデルの段階的廃止（特にOpenAI）
- バージョン間の互換性:
  - APIインターフェースの変更
  - レスポンスフォーマットの変更
  - 温度パラメータの扱いの違い（OpenAI reasoning）

## データ管理と結果比較

- バージョン間での結果比較:
  - モデルタイプによる評価基準の調整
  - 温度パラメータの有無による比較方法の変更
  - プロバイダ固有の特性の考慮
- データ保存と管理:
  - モデルタイプに応じた結果ファイル命名
  - 大量の実験データの効率的な保存
  - メタデータの一貫性確保

## 実験実行と最適化

- 実行時の課題:
  - プロバイダごとの異なるエラーハンドリング
  - API障害時の再試行戦略
  - 長時間実行時の安定性確保
- パフォーマンス最適化:
  - プロバイダごとの並列実行制限
  - メモリ使用量の管理
  - ネットワークタイムアウトの調整

## 結果分析と評価

- モデル間比較:
  - 異なるモデルタイプ間での公平な比較方法
  - 温度パラメータの有無による評価調整
  - プロバイダ固有の特性の考慮
- 評価基準:
  - 主観的評価の定量化手法
  - モデルタイプによる評価基準の調整
  - 結果の統計的有意性検証
- 特殊ケース:
  - OpenAI reasoningモデルの特殊な評価
  - Grokモデルの独自性への対応
  - 新規モデル追加時の比較方法更新
